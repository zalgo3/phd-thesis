\documentclass[../../main]{subfiles}

\begin{document}
\subsection{Merit functions for variational inequalities}
Merit functions have evolved in the context of reformulating variational inequalities (VIs) and complementarity problems (CPs) as optimization problems~\cite{Fukushima1996}.
The \emph{variational inequality} (VI) consists in finding~$x \in C$ such that
\[ \label{eq:VI}
    \innerp{T(x)}{y - x} \ge 0 \forallcondition{y \in C}
,\] 
where~$C \subseteq \setR^n$ is nonempty, closed, and convex, and~$T \colon \setR^n \to \setR^n$ is continuous.
We can also rewrite~\cref{eq:VI} as the following \emph{complementarity problem} (CP):
\[ \label{eq:CP}
    T(x) \ge 0, \quad x \ge 0, \eqand \innerp{T(x)}{x} \ge 0
.\] 
In particular, if~$T$ is affine, the we call~\cref{eq:CP} the \emph{linear complementarity problem} (LCP).
There are many merit functions for VIs and CPs, but here we illustrate the most basic two merit functions for VIs.

\begin{example}[Merit functions for the VI~\cref{eq:VI}] \label{ex:merit_VI}
    \begin{description}
        \item[The classical gap function~\cite{Auslender1976,Hearn1982}]
            We call the function~$G_0 \colon \setR^m \to \setR \cup \set{\infty}$ the \emph{classical gap function}:
            \[ \label{eq:gap}
                G_0(x) \coloneqq \sup_{y \in C} \innerp{T(x)}{x - y}
            .\] 
            It has the following properties:
            \begin{itemize}
                \item $G_0(x) \ge 0$ for all~$x \in C$;
                \item $G_0(x) = 0$ and~$x \in C$ if and only if~$x$ satisfies~\cref{eq:VI};
                \item If~$C$ is bounded,~$G_0$ is finite everywhere.
            \end{itemize}
            The top two indecate that~$G_0$ is a merit function for the VI~\cref{eq:VI}.
        \item[The regularized gap function~\cite{Fukushima1992,Auchmuty1989}]
            For a given parameter~$\alpha > 0$, we can consider the \emph{regularized gap function}~$G_\alpha \colon \setR^n \to \setR$ defined by
            \[ \label{eq:reg_gap}
                G_\alpha(x) \coloneqq \max_{y \in C} \left[ \innerp{T(x)}{x - y} - \frac{\alpha}{2} \norm{x - y}_2^2 \right] 
            ,\] 
            which is a merit function for the VI~\cref{eq:VI}, too.
            Since~\cref{eq:reg_gap} maximizes a strongly concave function on a nonempty, closed, and convex set, even if~$C$ is unbounded, an unique point attains the maximum, and~$G_\alpha$ is finite everywhere.
            Moreover, denoting such a maximizer by~$H_\alpha(x)$, if~$T$ is continuously differentiable,~$G_\alpha$ is also differentiable at any point~$x$, and we have
            \[
                \nabla G_\alpha(x) = T(x) - [ \jdv{T}{x} - \alpha I_n ] (H_\alpha(x) - x)
            .\] 
            Note that
            \[
                H_\alpha(x) = \proj_C(x - \alpha^{-1} T(x))
            .\] 
            Furthermore, if the Jacobian~$\jdv{T}{x}$ is positive definite on~$C$, any stationary point of the problem
            \[
                \min_{x \in C} \quad G_\alpha(x)
            \] 
            solves the VI~\cref{eq:VI}~\cite{Fukushima1992}.
            In addition, if~$T$ is strongly monotone with modulus~$\mu > 0$, i.e.,
            \[
                \innerp{T(x) - T(x')}{x - x'} > \mu \norm{x - x'}^2 \forallcondition{x, x' \in \setR^n}
            ,\]
            and if~$\alpha < 2 \mu$, then~$G_\alpha$ has the following error bound property~\cite{Taji1993}:
            \[
                \norm{x - x^\ast} \le \sqrt{\frac{G_\alpha(x)}{\mu - \alpha / 2}} \forallcondition{x \in S}
            ,\] 
            where~$x^\ast$ is the unique solution of the VI~\cref{eq:VI}.
    \end{description}
\end{example}

\end{document}

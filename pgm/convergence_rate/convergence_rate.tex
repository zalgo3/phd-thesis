\documentclass[../../main]{subfiles}

\begin{document}
\section{Convergence rates analysis} \label{sec:pgm:rate}
Let us now analyze the convergence rates of \cref{alg:pgm_MO}.
Define~$\psi_x \colon \setR^n \to \setR$ by
\begin{equation} \label{eq:psi}
    \psi_x(d) \coloneqq \max_{i = 1, \dots, m} \left[ \nabla f_i(x)^\T d + g_i(x + d) - g_i(x) \right].
\end{equation}
Looking at \cref{alg:pgm_MO} differently, it generates a sequence~$\{ x^k \}$ iteratively with the following procedure:
\[
    x^{k + 1} \coloneqq x^k + d^k,
\]
where~$d^k$ is a search direction.
At every iteration~$k$, we define this~$d^k$ by solving
\begin{equation} \label{eq:subprob}
    d^k \coloneqq \argmin_{d \in \setR^n} \left[ \psi_{x^k}(d) + \frac{\ell}{2} \norm*{ d }^2 \right],
\end{equation}
with a positive constant~$\ell > 0$.
Note that we have
\begin{equation} \label{eq:psi w_ell}
    \psi_{x^k}(d^k) + \frac{\ell}{2} \norm*{ d^k }^2 = - w_\ell(x^k),
\end{equation}
where~$w_\ell$ is defined by~\cref{eq:w_alpha}.
We suppose that the algorithm generates an infinite sequence of iterates from now on.
The following result shows an important property for~$\psi_x$.
\begin{lemma}[{\cite[Lemma~4.1]{Tanabe2019}}] \label{lem: psi property}
    Let~$\{ d^k \}$ be generated by \cref{alg:pgm_MO} and recall the definition~\cref{eq:psi} of~$\psi_x$. Then, we have
    \[
        \psi_{x^k}(d^k) \le - \ell \norm*{d^k}^2 \forallcondition{k}.
    \]
\end{lemma}
If~$\ell > L$, from \cref{thm:descent}, for all $i = 1, \dots, m$ we have
\begin{equation} \label{eq:descent}
    F_i(x^{k + 1}) - F_i(x^k) \le \innerp{\nabla f_i(x^k)}{d^k} + g_i(x^{k + 1}) - g_i(x^k) + \frac{\ell}{2}\norm*{d^k}.
\end{equation}
The right-hand side of~\cref{eq:descent} is less than zero since~$d^k$ is the optimal solution of~\cref{eq:subprob}, so we get
\begin{equation} \label{eq:nonincreasing}
    F_i(x^{k + 1}) \le F_i(x^k).
\end{equation}
\begin{remark}
    When the Lipschitz constant~$L$ is unknown or incomputable, we can use~$\ell$ for~\cref{eq:subprob} calculated by backtracking instead, i.e., we can set the initial value of~$\ell$ appropriately and multiply~$\ell$ by a prespecified scalar~$\gamma > 1$ at each iteration until~\cref{eq:descent} is satisfied.
    Since~$L$ is finite, the backtracking only requires a finite number of steps.
\end{remark}
\subfile{non_convex}
\subfile{convex}
\subfile{strongly_convex}
\subfile{prox_PL}

\end{document}

\documentclass[../../main]{subfiles}

\begin{document}
\subsection{A gap function for continuous multi-objective optimization} \zlabel{sec:merit:merit:gap}
First, we assume only continuity on~$F$ other than continuity and propose a gap function~$u_0 \colon C \to (-\infty, +\infty]$ as follows:
\begin{equation} \label{eq:gap_MO}
    u_0(x) \coloneqq \sup_{y \in C} \min_{i = 1, \dots, m} [ F_i(x) - F_i(y) ] 
.\end{equation}
When~$F$ is linear, this merit function has already been discussed in~\cite{Liu2009}, but here we consider the more general nonlinear cases.
We now show that $u_0$ is a merit function in the sense of weak Pareto optimality.
\begin{theorem} \zlabel{thm:gap}
    Let~$u_0$ be defined by~\zcref{eq:gap_MO}.
    Then, we have~$u_0(x) \ge 0$ for all~$x \in C$.
    Moreover,~$x \in C$ is weakly Pareto optimal for~\zcref{eq:MOO} if and only if~$u_0(x) = 0$.
\end{theorem}
\begin{proof}
    Let~$x \in C$.
    By the definition~\zcref{eq:gap_MO} of~$u_0$, we get
    \begin{equation}
        u_0(x) = \sup_{y \in C} \min_{i = 1, \dots, m} [ F_i(x) - F_i(y) ]
                 \ge \min_{i = 1, \dots, m} [ F_i(x) - F_i(x) ] = 0
    .\end{equation} 
    On the other hand, again considering the definition~\zcref{eq:gap_MO} of~$u_0$, we obtain
    \begin{equation}
        u_0(x) = 0 \iff \min_{i = 1, \dots, m} [ F_i(x) - F_i(y) ] \le 0 \forallcondition{y \in C}
    .\end{equation} 
    This is equivalent to the existence of~$i = 1, \dots, m$ such that
    \begin{equation}
        F_i(x) - F_i(y) \le 0 \forallcondition{y \in C}
    ,\end{equation} 
    i.e., there does not exist~$y \in C$ such that
    \begin{equation}
        F_i(x) - F_i(y) > 0 \forallcondition{i = 1, \dots, m}
    ,\end{equation} 
    which means that~$x$ is weakly Pareto optimal for~\zcref{eq:MOO} by \zcref{def:Pareto:Pareto}.
\end{proof}

The following theorem is clear from the continuity of~$F_i$.
\begin{theorem} \zlabel{thm:cont_u_0}
    The function~$u_0$ defined by~\zcref{eq:gap_MO} is lower semicontinuous on~$C$.
\end{theorem}
\zcref{thm:cont_u_0,thm:gap} imply that if~$u_0(x^k) \to 0$ holds for some bounded sequence~$\set{x^k}$, its accumulation points are weakly Pareto optimal.
Thus, we can use~$u_0$ to measure the complexity of multi-objective optimization methods.

Moreover, \zcref{thm:gap} implies that we can get weakly Pareto optimal solutions via the following single-objective optimization problem:
\begin{equation}
    \min_{x \in C} \quad u_0(x)
.\end{equation} 
However, if~$F_i$ is not bounded from below on~$S$, we cannot guarantee that~$u_0$ is finite-valued.
Moreover, even if~$u_0$ is finite-valued,~$u_0$ does not preserve the differentiability of the original objective function~$F$.

\end{document}
